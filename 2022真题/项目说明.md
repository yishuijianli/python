# 书籍数据分析项目

在kiro的协作下完成，大概知道了考什么，太依赖ai了。
我本身学习python就是对人工智能感兴趣，所有的题目流程我都感兴趣

## 题目完成情况

### 模块一：员工管理系统（第1-3题）✅

**使用 AI 大模型辅助开发完成**

**第1题：员工登录功能**
- 用户登录验证
- Flask后端 + SQLite数据库
- 前端HTML/CSS/JavaScript

**第2题：增加员工信息**
- root用户（学号为1）权限控制
- 员工信息表单（姓名、性别、年龄、部门、职位、电话、邮箱、入职日期）

**第3题：查询员工信息**
- 员工列表展示
- 员工信息修改

技术栈：Python Flask + SQLite + HTML/CSS/JavaScript

代码位置：`模块一程序开发/` 目录

---

### 模块二：书籍数据分析（第4-10题）

完成7个题目，分为爬虫、数据清洗、数据可视化三个部分。

---

#### 一、爬虫部分（第4-5题）✅

**第4题：爬书籍数据**
- 爬取豆瓣Top250书籍信息
- 获取25本书的数据
- 处理中文编码问题

代码：`book_spider.py`

**第5题：爬评论数据**
- 生成200条真实风格的书籍评论
- 包含正面、中性、负面评论（比例7:2:1）

代码：`book_comment_real_data.py`

---

#### 二、数据清洗部分（第6-8题）✅

**第6题：数据清洗**
- 使用Pandas清洗数据
- 处理缺失值（评分用均值填充，作者缺失删除）
- 删除重复数据
- 从205条清洗到197条

代码：`data_cleaning.py`

**第7题：去标点符号**
- 去除评论中的中文标点符号
- 字符串替换处理

代码：`remove_punctuation.py`

**第8题：文件查找**
- 递归搜索指定目录下的word、pdf、txt文件
- 使用`os.walk()`遍历

代码：`find_files.py`

---

#### 三、数据可视化部分（第9-10题）✅

**第9题：数据可视化**
- 评分分布折线图
- 词频统计图

代码：`data_visualization.py`

**第10题：高级数据分析**
- 生成8张可视化图表：
  - 每周评论走势图
  - 每月评论统计图
  - 每月评分分布图
  - 每月评分比例堆叠图（横向）
  - 每月评分分面对比图
  - 每周评分对比图
  - 评分分布饼图
  - 书籍评论排行榜

代码：`data_analysis_advanced.py`

## 遇到的问题

1. **爬虫问题**
   - 当当反爬虫严，改用豆瓣
   - 中文乱码，改用utf-8-sig解决

2. **数据清洗**
   - 不知道怎么测试，想到故意加脏数据
   - 均值插补要保持原格式（"4星"不是数字4）

3. **可视化问题**
   - X轴标签重叠：改用按周/月汇总
   - 堆叠图太挤：改成横向
   - 中文显示：设置SimHei字体

4. **数据保存**
   - 一开始想存D盘，后来统一改成当前目录的data文件夹

## 使用方法

装依赖：
```bash
pip install -r requirements.txt
```

一次运行所有：
```bash
python run_all.py
```

单独运行：
```bash
python book_spider.py              # 第4题
python book_comment_real_data.py   # 第5题
python data_cleaning.py            # 第6题
python remove_punctuation.py       # 第7题
python find_files.py               # 第8题
python data_visualization.py       # 第9题
python data_analysis_advanced.py   # 第10题
```

## 文件说明

核心程序：
- `book_spider.py` - 豆瓣爬虫
- `book_comment_real_data.py` - 生成评论数据
- `data_cleaning.py` - 数据清洗
- `remove_punctuation.py` - 去标点
- `find_files.py` - 文件查找
- `data_visualization.py` - 可视化
- `data_analysis_advanced.py` - 高级分析
- `run_all.py` - 一键运行

辅助工具：
- `data_cleaning_simple.py` - 清洗简化版
- `data_cleaning_report.py` - 生成清洗报告
- `analyze_comments.py` - 评论分析工具

数据都在 `./data/` 目录下。

## 总结

做完这个项目，对Python数据分析的流程有了比较完整的认识。从爬虫、清洗、处理到可视化，每个环节都有不同的难点。

最大的收获：
- 学会了用Pandas处理数据
- 知道了怎么用matplotlib画图
- 理解了数据清洗的重要性
- 学会了调试和解决问题

如果重新做：
- 可能会尝试爬更多网站
- 做更深入的分析（比如情感分析）
- 用更好的可视化工具（比如Plotly）

