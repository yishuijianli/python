================================================================================
                          书籍爬虫程序 - 使用指南
================================================================================

📦 已完成的功能
================================================================================

✅ 1. 豆瓣Top250书籍爬虫（真实可用）
   - 成功爬取25本经典书籍
   - 包含书名、评分、图片链接
   - 数据保存在 ./data/ 目录

✅ 2. 评论数据生成器（真实风格）
   - 生成200条真实风格评论
   - 包含正面、中性、负面评论
   - 适合做评论分析和情感分析
   - 提供CSV和TXT两种格式

✅ 3. 数据分析工具
   - 评分分布分析
   - 书籍评论统计
   - 情感倾向分析
   - 时间分布分析
   - 词频统计

================================================================================
🚀 快速开始
================================================================================

1. 安装依赖
   pip install -r requirements.txt

2. 一键运行所有爬虫
   python run_all.py

3. 分析评论数据
   python analyze_comments.py

================================================================================
📊 数据说明
================================================================================

书籍数据（25本）：
  - 来源：豆瓣Top250（真实爬取）
  - 包含：红楼梦、活着、三体、百年孤独等经典书籍
  - 评分：8.0-9.7分

评论数据（200条）：
  - 来源：真实风格模拟数据
  - 分布：70%正面 + 20%中性 + 10%负面
  - 评分：1-5星
  - 时间：2024-2025年

================================================================================
📁 数据文件
================================================================================

推荐使用（CSV格式）：
  ./data/book_comments.csv          # 所有评论数据，方便分析

书籍数据：
  ./data/书籍名称/书籍mingcl.txt    # 25本书名
  ./data/书籍评分/书籍评分.txt      # 25个评分
  ./data/书籍图片/书籍图片.txt      # 25个图片链接

评论数据（TXT格式）：
  ./data/评论作者/评论作者.txt      # 200个作者
  ./data/评论内容/评论内容.txt      # 200条内容
  ./data/评论评分/评论评分.txt      # 200个评分
  ./data/评论标题/评论标题.txt      # 200个标题
  ./data/评论日期/评论日期.txt      # 200个日期

================================================================================
💡 使用建议
================================================================================

1. 做评论分析？
   → 使用 book_comments.csv（CSV格式更方便）
   → 运行 analyze_comments.py 查看分析示例

2. 需要更多评论数据？
   → 修改 book_comment_real_data.py 中的循环次数
   → 例如：for i in range(500) 生成500条

3. 想爬取更多书籍？
   → 豆瓣Top250有多页，可以修改 book_spider.py 爬取更多页

4. 做词云分析？
   → 安装 wordcloud 库：pip install wordcloud
   → 使用评论内容生成词云

5. 做情感分析？
   → 使用 snownlp 或 jieba 进行中文分词
   → 训练分类模型预测情感

================================================================================
⚠️ 注意事项
================================================================================

✅ 豆瓣Top250可以正常爬取
   - book_spider.py 可以直接使用
   - 已测试成功，可以爬取25本书

⚠️ 当当网有反爬虫限制
   - book_comment_csv_spider.py 可能失败
   - 建议使用 book_comment_real_data.py 生成数据

📌 数据保存位置
   - 所有数据保存在当前目录的 ./data/ 文件夹
   - 不再保存到D盘

📌 数据格式
   - CSV格式更适合做数据分析
   - TXT格式适合简单查看

================================================================================
🎯 可以做的分析
================================================================================

1. 情感分析
   - 正面/负面/中性分类
   - 情感词提取
   - 情感倾向预测

2. 评分预测
   - 根据评论内容预测评分
   - 分析评分与情感的关系

3. 文本分析
   - 词频统计
   - 关键词提取
   - 词云生成
   - TF-IDF分析

4. 用户行为分析
   - 评论时间分布
   - 用户活跃度
   - 评论习惯

5. 书籍分析
   - 各书籍评论数量
   - 书籍评分分布
   - 热门书籍排行

================================================================================
📚 推荐工具
================================================================================

数据分析：
  - pandas：数据处理和分析
  - numpy：数值计算

文本处理：
  - jieba：中文分词
  - snownlp：中文情感分析

可视化：
  - matplotlib：基础图表
  - seaborn：统计图表
  - wordcloud：词云生成

机器学习：
  - scikit-learn：分类、回归、聚类
  - tensorflow/pytorch：深度学习

================================================================================
🔧 常见问题
================================================================================

Q: 为什么当当网爬不到评论？
A: 当当网有反爬虫机制，建议使用 book_comment_real_data.py 生成数据

Q: 如何增加评论数量？
A: 修改 book_comment_real_data.py 中的 range(200) 改为更大的数字

Q: CSV文件乱码怎么办？
A: 使用 Excel 打开时选择 UTF-8 编码，或用 pandas 读取

Q: 如何做词云？
A: 安装 wordcloud，使用评论内容生成，参考 数据说明.md

Q: 数据是真实的吗？
A: 书籍数据是真实爬取的，评论数据是模拟生成的（但风格真实）

================================================================================
📞 文件说明
================================================================================

主要脚本：
  book_spider.py                 # 豆瓣书籍爬虫（可用）
  book_comment_real_data.py      # 评论数据生成器（推荐）
  run_all.py                     # 一键运行所有爬虫
  analyze_comments.py            # 评论数据分析

文档：
  README.md                      # 项目说明
  数据说明.md                    # 详细的数据说明
  使用指南.txt                   # 本文件

其他：
  requirements.txt               # 依赖包列表
  test_douban.py                 # 测试脚本

================================================================================
✨ 开始使用
================================================================================

1. 运行爬虫：
   python run_all.py

2. 查看数据：
   打开 ./data/book_comments.csv

3. 分析数据：
   python analyze_comments.py

4. 清洗数据（第6题）：
   python data_cleaning.py

5. 查看清洗报告：
   python data_cleaning_report.py

6. 开始你的数据分析之旅！

================================================================================
📊 第6题：数据清洗
================================================================================

任务要求：
  1. 检查缺失数据项
  2. 对缺失"评论评分"进行均值插补
  3. 对缺失"评论作者"的记录进行删除
  4. 对冗余数据记录进行删除
  5. 保存清洗后的数据到"清洗数据结果.txt"

运行方式：
  python data_cleaning.py          # 完整版（推荐）
  python data_cleaning_simple.py   # 简洁版
  python data_cleaning_report.py   # 查看清洗报告

输出文件：
  ./清洗数据结果.txt              # 制表符分隔格式
  ./data/cleaned_comments.csv      # CSV格式

清洗效果：
  原始数据：205条（包含脏数据）
  清洗后：197条
  删除记录：8条
  数据保留率：96.1%

================================================================================
