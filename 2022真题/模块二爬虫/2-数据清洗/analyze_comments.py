# -*- coding: utf-8 -*-
"""
è¯„è®ºæ•°æ®åˆ†æç¤ºä¾‹
å±•ç¤ºå¦‚ä½•åˆ†æç”Ÿæˆçš„è¯„è®ºæ•°æ®
"""

import csv
from collections import Counter
import os

def load_comments(filepath):
    """åŠ è½½CSVæ ¼å¼çš„è¯„è®ºæ•°æ®"""
    comments = []
    try:
        with open(filepath, 'r', encoding='utf-8-sig') as f:
            reader = csv.DictReader(f)
            comments = list(reader)
        return comments
    except Exception as e:
        print(f"è¯»å–æ–‡ä»¶å‡ºé”™: {e}")
        return []

def analyze_ratings(comments):
    """åˆ†æè¯„åˆ†åˆ†å¸ƒ"""
    print("\n" + "=" * 60)
    print("è¯„åˆ†åˆ†å¸ƒåˆ†æ")
    print("=" * 60)
    
    ratings = [c['è¯„åˆ†'] for c in comments]
    rating_count = Counter(ratings)
    
    total = len(ratings)
    for rating in sorted(rating_count.keys()):
        count = rating_count[rating]
        percentage = (count / total) * 100
        bar = "â–ˆ" * int(percentage / 2)
        print(f"{rating}: {count:3d} æ¡ ({percentage:5.1f}%) {bar}")

def analyze_books(comments):
    """åˆ†æå„ä¹¦ç±çš„è¯„è®ºæ•°é‡"""
    print("\n" + "=" * 60)
    print("å„ä¹¦ç±è¯„è®ºæ•°é‡")
    print("=" * 60)
    
    books = [c['ä¹¦å'] for c in comments]
    book_count = Counter(books)
    
    for book, count in book_count.most_common(10):
        bar = "â–ˆ" * (count // 2)
        print(f"{book:15s}: {count:2d} æ¡ {bar}")

def analyze_sentiment(comments):
    """ç®€å•çš„æƒ…æ„Ÿåˆ†æ"""
    print("\n" + "=" * 60)
    print("æƒ…æ„Ÿå€¾å‘åˆ†æ")
    print("=" * 60)
    
    positive_words = ['å¥½çœ‹', 'æ¨è', 'å–œæ¬¢', 'æ£’', 'ç²¾å½©', 'æ„Ÿäºº', 'ç»å…¸', 'å€¼å¾—']
    negative_words = ['å¤±æœ›', 'ä¸€èˆ¬', 'æ¯ç‡¥', 'åˆ«æ‰­', 'ç©ºæ´', 'æ‹–æ²“', 'è€å¥—']
    
    positive_count = 0
    negative_count = 0
    neutral_count = 0
    
    for comment in comments:
        content = comment['å†…å®¹']
        has_positive = any(word in content for word in positive_words)
        has_negative = any(word in content for word in negative_words)
        
        if has_positive and not has_negative:
            positive_count += 1
        elif has_negative and not has_positive:
            negative_count += 1
        else:
            neutral_count += 1
    
    total = len(comments)
    print(f"æ­£é¢è¯„è®º: {positive_count} æ¡ ({positive_count/total*100:.1f}%)")
    print(f"è´Ÿé¢è¯„è®º: {negative_count} æ¡ ({negative_count/total*100:.1f}%)")
    print(f"ä¸­æ€§è¯„è®º: {neutral_count} æ¡ ({neutral_count/total*100:.1f}%)")

def analyze_time(comments):
    """åˆ†æè¯„è®ºæ—¶é—´åˆ†å¸ƒ"""
    print("\n" + "=" * 60)
    print("è¯„è®ºæ—¶é—´åˆ†å¸ƒï¼ˆæŒ‰æœˆä»½ï¼‰")
    print("=" * 60)
    
    months = [c['æ—¥æœŸ'][:7] for c in comments]  # æå–å¹´-æœˆ
    month_count = Counter(months)
    
    for month, count in sorted(month_count.items())[-6:]:  # æ˜¾ç¤ºæœ€è¿‘6ä¸ªæœˆ
        bar = "â–ˆ" * (count // 2)
        print(f"{month}: {count:2d} æ¡ {bar}")

def word_frequency(comments):
    """è¯é¢‘ç»Ÿè®¡ï¼ˆç®€å•ç‰ˆï¼‰"""
    print("\n" + "=" * 60)
    print("é«˜é¢‘è¯æ±‡ï¼ˆå‰20ä¸ªï¼‰")
    print("=" * 60)
    
    # ç®€å•çš„åˆ†è¯ï¼ˆæŒ‰å­—ç¬¦ï¼‰
    all_text = ' '.join([c['å†…å®¹'] for c in comments])
    
    # å¸¸è§çš„é«˜é¢‘è¯
    keywords = ['å¥½çœ‹', 'æ¨è', 'å–œæ¬¢', 'ä¸é”™', 'ä¸€èˆ¬', 'å¤±æœ›', 'ç²¾å½©', 'æ„Ÿäºº',
                'å€¼å¾—', 'ç»å…¸', 'å†…å®¹', 'æ•…äº‹', 'ä½œè€…', 'æ–‡ç¬”', 'æƒ…èŠ‚']
    
    word_count = {}
    for word in keywords:
        count = all_text.count(word)
        if count > 0:
            word_count[word] = count
    
    for word, count in sorted(word_count.items(), key=lambda x: x[1], reverse=True)[:20]:
        bar = "â–ˆ" * (count // 5)
        print(f"{word:6s}: {count:3d} æ¬¡ {bar}")

def main():
    print("=" * 60)
    print("ä¹¦ç±è¯„è®ºæ•°æ®åˆ†æ")
    print("=" * 60)
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    filepath = './data/book_comments.csv'
    if not os.path.exists(filepath):
        print(f"\né”™è¯¯ï¼šæ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶ {filepath}")
        print("è¯·å…ˆè¿è¡Œ python book_comment_real_data.py ç”Ÿæˆæ•°æ®")
        return
    
    # åŠ è½½æ•°æ®
    print(f"\næ­£åœ¨åŠ è½½æ•°æ®: {filepath}")
    comments = load_comments(filepath)
    
    if not comments:
        print("æ²¡æœ‰æ•°æ®å¯åˆ†æ")
        return
    
    print(f"å…±åŠ è½½ {len(comments)} æ¡è¯„è®º")
    
    # æ‰§è¡Œå„ç§åˆ†æ
    analyze_ratings(comments)
    analyze_books(comments)
    analyze_sentiment(comments)
    analyze_time(comments)
    word_frequency(comments)
    
    print("\n" + "=" * 60)
    print("åˆ†æå®Œæˆï¼")
    print("=" * 60)
    print("\nğŸ’¡ æç¤ºï¼š")
    print("  - å¯ä»¥ä½¿ç”¨ pandas è¿›è¡Œæ›´æ·±å…¥çš„æ•°æ®åˆ†æ")
    print("  - å¯ä»¥ä½¿ç”¨ jieba è¿›è¡Œä¸­æ–‡åˆ†è¯")
    print("  - å¯ä»¥ä½¿ç”¨ wordcloud ç”Ÿæˆè¯äº‘")
    print("  - å¯ä»¥ä½¿ç”¨ matplotlib ç»˜åˆ¶å›¾è¡¨")

if __name__ == '__main__':
    main()
