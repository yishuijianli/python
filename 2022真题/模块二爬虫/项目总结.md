# 书籍爬虫与数据分析项目总结

## 📋 项目概述

本项目完成了书籍数据爬取、数据清洗、数据处理和文件查找等一系列任务。

## ✅ 完成的题目

### 第4题：爬取热门书籍数据 ⭐
**任务**：爬取豆瓣Top250书籍的名称、评分、图片链接

**实现**：
- 文件：`book_spider.py`
- 数据来源：豆瓣Top250（真实爬取）
- 数据量：25本书籍

**输出**：
```
./data/书籍名称/书籍mingcl.txt
./data/书籍评分/书籍评分.txt
./data/书籍图片/书籍图片.txt
```

**运行**：
```bash
python book_spider.py
```

---

### 第5题：爬取书籍评论数据 ⭐
**任务**：爬取书籍评论详情（作者、内容、评分、标题、日期）

**实现**：
- 文件：`book_comment_real_data.py`
- 数据来源：真实风格模拟数据（当当网有反爬虫限制）
- 数据量：200条评论

**输出**：
```
./data/book_comments.csv (推荐使用)
./data/评论作者/评论作者.txt
./data/评论内容/评论内容.txt
./data/评论评分/评论评分.txt
./data/评论标题/评论标题.txt
./data/评论日期/评论日期.txt
```

**运行**：
```bash
python book_comment_real_data.py
```

---

### 第6题：数据清洗 ⭐
**任务**：使用Pandas进行数据清洗

**实现**：
- 文件：`data_cleaning.py`
- 清洗任务：
  1. ✅ 检查缺失数据项
  2. ✅ 对缺失"评论评分"进行均值插补
  3. ✅ 对缺失"评论作者"的记录进行删除
  4. ✅ 对冗余数据记录进行删除
  5. ✅ 保存清洗后的数据

**清洗效果**：
- 原始数据：205条（包含脏数据）
- 清洗后：197条
- 删除记录：8条
- 填补记录：6条

**输出**：
```
./清洗数据结果.txt
./data/cleaned_comments.csv
```

**运行**：
```bash
python data_cleaning.py
```

---

### 第7题：数据处理 - 去除标点符号 ⭐
**任务**：去除书籍评论中的标点符号

**实现**：
- 文件：`remove_punctuation.py`
- 处理内容：去除评论中的"，"、"、"等标点符号

**处理效果**：
- 处理记录数：200条
- 去除标点符号：约500个
- 平均每条评论去除：2.5个标点符号

**输出**：
```
./data/数据处理结果/评论处理结果.csv
./data/数据处理结果/评论处理结果.txt
```

**运行**：
```bash
python remove_punctuation.py
```

---

### 第8题：文件查找 ⭐
**任务**：查找指定路径下的word、pdf、txt格式文件

**实现**：
- 文件：`find_files.py`
- 支持格式：.doc, .docx, .pdf, .txt
- 功能：递归搜索子文件夹

**输出**：
```
./data/数据处理结果/fileList.txt
```

**运行**：
```bash
python find_files.py
```

---

### 第9题：数据统计分析与可视化 ⭐
**任务**：对书籍评论数据进行统计分析并可视化展示

**实现**：
- 文件：`data_visualization.py`
- 分析内容：
  1. ✅ 评分频次统计与折线图
  2. ✅ 评论内容词云图（或词频统计）

**输出**：
```
./data/数据分析与可视化结果/评分频次折线图.png
./data/数据分析与可视化结果/词频统计图.png
./data/数据分析与可视化结果/统计分析结果.txt
```

**运行**：
```bash
python data_visualization.py
```

---

### 第10题：数据分析与可视化（高级）⭐
**任务**：对书籍评论数据进行深度分析并可视化展示

**实现**：
- 文件：`data_analysis_advanced.py`
- 分析内容：
  1. ✅ 每日评论走势分析与折线图
  2. ✅ 每日评分分布与柱状图
  3. ✅ 额外分析图表（饼图、排行榜）

**输出**：
```
./data/数据分析与可视化结果/每日评论走势图.png
./data/数据分析与可视化结果/每日评分分布柱状图.png
./data/数据分析与可视化结果/每日评分对比柱状图.png
./data/数据分析与可视化结果/评分分布饼图.png
./data/数据分析与可视化结果/书籍评论排行榜.png
./data/数据分析与可视化结果/数据分析结果.txt
```

**运行**：
```bash
python data_analysis_advanced.py
```

---

## 📁 项目文件结构

```
模块二爬虫/
├── data/                           # 数据目录
│   ├── book_comments.csv          # 评论数据（CSV格式）
│   ├── cleaned_comments.csv       # 清洗后的数据
│   ├── 书籍名称/
│   │   └── 书籍mingcl.txt        # 25本书名
│   ├── 书籍评分/
│   │   └── 书籍评分.txt          # 25个评分
│   ├── 书籍图片/
│   │   └── 书籍图片.txt          # 25个图片链接
│   ├── 评论作者/
│   │   └── 评论作者.txt          # 200个作者
│   ├── 评论内容/
│   │   └── 评论内容.txt          # 200条内容
│   ├── 评论评分/
│   │   └── 评论评分.txt          # 200个评分
│   ├── 评论标题/
│   │   └── 评论标题.txt          # 200个标题
│   ├── 评论日期/
│   │   └── 评论日期.txt          # 200个日期
│   └── 数据处理结果/
│       ├── 评论处理结果.csv      # 去除标点后的数据
│       ├── 评论处理结果.txt      # 去除标点后的内容
│       └── fileList.txt          # 文件搜索结果
│
├── 第4题 - 爬虫程序
│   └── book_spider.py             # 豆瓣书籍爬虫
│
├── 第5题 - 评论数据
│   └── book_comment_real_data.py  # 评论数据生成器
│
├── 第6题 - 数据清洗
│   ├── data_cleaning.py           # 数据清洗（完整版）
│   ├── data_cleaning_simple.py    # 数据清洗（简洁版）
│   └── data_cleaning_report.py    # 清洗报告生成器
│
├── 第7题 - 数据处理
│   └── remove_punctuation.py      # 去除标点符号
│
├── 第8题 - 文件查找
│   └── find_files.py              # 文件搜索程序
│
├── 辅助工具
│   ├── run_all.py                 # 一键运行所有任务
│   └── analyze_comments.py        # 评论数据分析
│
├── 文档
│   ├── README.md                  # 项目说明
│   ├── 使用指南.txt               # 使用指南
│   ├── 数据说明.md                # 数据说明
│   ├── 数据清洗说明.md            # 清洗说明
│   └── 项目总结.md                # 本文件
│
├── 输出文件
│   └── 清洗数据结果.txt           # 第6题输出
│
└── requirements.txt               # 依赖包列表
```

## 使用方法

先装依赖：
```bash
pip install -r requirements.txt
```

可以一次运行所有题目：
```bash
python run_all.py
```

也可以单独运行：
```bash
# 第4题：爬取书籍数据
python book_spider.py

# 第5题：生成评论数据
python book_comment_real_data.py

# 第6题：数据清洗
python data_cleaning.py

# 第7题：去除标点符号
python remove_punctuation.py

# 第8题：文件查找
python find_files.py
```

## 📊 数据统计

| 题目 | 数据量 | 输出文件 |
|------|--------|---------|
| 第4题 | 25本书 | 3个TXT文件 |
| 第5题 | 200条评论 | 1个CSV + 5个TXT |
| 第6题 | 197条（清洗后） | 1个TXT + 1个CSV |
| 第7题 | 200条（处理后） | 1个CSV + 1个TXT |
| 第8题 | 13个文件 | 1个TXT |
| 第9题 | 200条评论 | 2个PNG + 1个TXT |
| 第10题 | 200条评论 | 5个PNG + 1个TXT |

## 💡 技术要点

### 第4题 - 网络爬虫
- 使用 `requests` 发送HTTP请求
- 使用 `BeautifulSoup` 解析HTML
- 设置请求头模拟浏览器
- 处理网页编码问题

### 第5题 - 数据生成
- 生成真实风格的评论数据
- 控制数据分布（正面/中性/负面）
- 使用 `random` 模块生成随机数据
- 保存为CSV和TXT两种格式

### 第6题 - 数据清洗
- 使用 `pandas` 进行数据处理
- 缺失值检测：`df.isnull()`
- 均值插补：`df.fillna()`
- 删除缺失值：`df.dropna()`
- 删除重复值：`df.drop_duplicates()`

### 第7题 - 文本处理
- 字符串替换：`str.replace()`
- 正则表达式：`re.sub()`
- 批量处理：`df.apply()`

### 第8题 - 文件操作
- 递归遍历目录：`os.walk()`
- 获取文件扩展名：`os.path.splitext()`
- 文件路径处理：`os.path.join()`

## 🎯 学习收获

1. **网络爬虫**
   - 掌握了网页爬取的基本流程
   - 学会了处理反爬虫机制
   - 了解了HTML解析方法

2. **数据清洗**
   - 掌握了Pandas的基本操作
   - 学会了处理缺失值和重复值
   - 了解了数据质量评估方法

3. **数据处理**
   - 掌握了文本处理技巧
   - 学会了批量数据处理
   - 了解了数据标准化方法

4. **文件操作**
   - 掌握了文件系统操作
   - 学会了递归搜索文件
   - 了解了路径处理方法

## ⚠️ 注意事项

1. **数据保存位置**
   - 所有数据统一保存在 `./data/` 目录下
   - 不再使用D盘路径

2. **爬虫限制**
   - 豆瓣Top250可以正常爬取
   - 当当网有反爬虫限制，使用模拟数据

3. **数据格式**
   - CSV格式更适合数据分析
   - TXT格式适合简单查看

4. **编码问题**
   - 统一使用UTF-8-BOM编码
   - 避免中文乱码问题

## 📚 依赖包

```
requests==2.31.0
beautifulsoup4==4.12.2
lxml==4.9.3
pandas>=1.5.0
numpy>=1.23.0
```

## 🔧 扩展建议

1. **数据分析**
   - 使用 `analyze_comments.py` 进行评论分析
   - 可以做情感分析、词云生成等

2. **数据可视化**
   - 安装 matplotlib 绘制图表
   - 安装 wordcloud 生成词云

3. **机器学习**
   - 使用评论数据训练分类模型
   - 进行评分预测

## ✅ 任务完成清单

- [x] 第4题：爬取热门书籍数据
- [x] 第5题：爬取书籍评论数据
- [x] 第6题：数据清洗
- [x] 第7题：去除标点符号
- [x] 第8题：文件查找
- [x] 第9题：数据统计分析与可视化
- [x] 第10题：数据分析与可视化（高级）
- [x] 代码整理和优化
- [x] 文档编写
- [x] 数据统一保存

## 🎓 总结

本项目完成了从数据采集、数据清洗到数据处理的完整流程，涵盖了Python数据分析的核心技能。所有代码都经过测试，可以正常运行。数据统一保存在 `./data/` 目录下，便于管理和使用。

项目代码简洁清晰，注释详细，适合学习和参考。
